{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hw5-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCXJOIMyZlX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pymorphy2\n",
        "!pip install pyLDAvis\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13mvGK3UZjG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import pyLDAvis.gensim\n",
        "import string\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import google.colab\n",
        "\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u443xcdHbFL6",
        "colab_type": "code",
        "outputId": "2fa73f54-946f-49ea-ff7a-77f04b1f7774",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-47b86729-9a76-4da0-9d31-31b5c7249ecf\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-47b86729-9a76-4da0-9d31-31b5c7249ecf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving habr_texts.txt to habr_texts.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py0gQEeftX2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = open('habr_texts.txt').read().splitlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNrAge_ZsxCf",
        "colab_type": "text"
      },
      "source": [
        "Нормализуем"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JRmTBEsaH8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stops = set(stopwords.words('russian')) | {'gt',}\n",
        "def remove_tags(text):\n",
        "    return re.sub(r'<[^>]+>', '', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNcD9LgsbAyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def opt_normalize(texts, top=None):\n",
        "    uniq = Counter()\n",
        "    for text in texts:\n",
        "        uniq.update(text)\n",
        "    \n",
        "    norm_uniq = {word:morph.parse(word)[0].normal_form for word, _ in uniq.most_common(top)}\n",
        "    \n",
        "    norm_texts = []\n",
        "    for text in texts:\n",
        "        \n",
        "        norm_words = [norm_uniq.get(word) for word in text]\n",
        "        norm_words = [word for word in norm_words if word and word not in stops]\n",
        "        norm_texts.append(norm_words)\n",
        "        \n",
        "    return norm_texts\n",
        "\n",
        "def tokenize(text):\n",
        "    words = [word.strip(string.punctuation) for word in text.split()]\n",
        "    words = [word for word in words if word]\n",
        "    \n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSsPCxV7bEjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = opt_normalize([tokenize(remove_tags(text.lower())) for text in texts], 30000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpExd-Jmth-d",
        "colab_type": "text"
      },
      "source": [
        "N-граммы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIKjoTkPtkn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ph = gensim.models.Phrases(texts, scoring='npmi', min_count=1, threshold=1) \n",
        "p = gensim.models.phrases.Phraser(ph)\n",
        "ngrammed_texts = p[texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaqEeaZpxo4F",
        "colab_type": "text"
      },
      "source": [
        "Словарь"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6WVg1lEkngV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary(ngrammed_texts)\n",
        "dictionary.filter_extremes(no_above=0.1, no_below=20)\n",
        "dictionary.compactify()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebtgZMRfku7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [dictionary.doc2bow(text) for text in ngrammed_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8N1B1n0AgIf",
        "colab_type": "text"
      },
      "source": [
        "LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eDK6VHymY0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda = gensim.models.LdaMulticore(corpus, 100, id2word=dictionary, eval_every=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoFeZkVxhB3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda.print_topics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYt50o2-WXW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "88002bde-6412-4c0e-a457-9e01c97224c3"
      },
      "source": [
        "lda.log_perplexity(corpus[:10000])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-63.61912846747557"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14apa27ti8vS",
        "colab_type": "text"
      },
      "source": [
        "Попробую поменять параметры модели. Уменьшим число тем и добавим параметры passes, alpha"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYBghZle6TOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda2 = gensim.models.LdaMulticore(corpus, id2word=dictionary, eval_every=1, num_topics=20, passes=3, alpha='asymmetric')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OL57qVYhFmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda2.print_topics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAG8Yb0fWy3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d669b127-9939-4d04-bf33-96bfe9b357ff"
      },
      "source": [
        "lda2.log_perplexity(corpus[:10000])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-10.237877543213191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wo_G6aVju60",
        "colab_type": "text"
      },
      "source": [
        "Уменьшим число тем, увеличим passes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3sJd2qhK0hU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda3 = gensim.models.LdaMulticore(corpus, id2word=dictionary, eval_every=1, num_topics=10, passes=5, alpha='asymmetric')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKFGcprrhKFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda3.print_topics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwCkmzXzXIb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "444fac34-af1d-4f58-a8b7-86bfedcb544d"
      },
      "source": [
        "lda3.log_perplexity(corpus[:10000])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-9.690283925672029"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdChdZu9jHRe",
        "colab_type": "text"
      },
      "source": [
        "Уменьшение количества тем, по-видимому, не очень хорошо сказывается на результатах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8tpK0FmipsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda4 = gensim.models.LdaMulticore(corpus, id2word=dictionary, eval_every=1, num_topics=100, passes=5, alpha='asymmetric')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEp1DNmFisd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda4.print_topics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSCAv-RIXYfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "86766735-7628-4390-ce4c-f82efa6b765c"
      },
      "source": [
        "lda4.log_perplexity(corpus[:10000])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-11.763155684005355"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQNamDGlHzeB",
        "colab_type": "text"
      },
      "source": [
        "Самые, на мой взгляд, убедительные темы появились в lda4. Вот некоторые из них:\n",
        "(98,\n",
        "  '0.112*\"вакансия\" + 0.026*\"выборка\" + 0.026*\"навык\" + 0.017*\"москва\" + 0.016*\"рубль\" + 0.015*\"зарплата\" + 0.013*\"распределение\" + 0.012*\"профессиональный\" + 0.012*\"плата\" + 0.011*\"работодатель\"')\n",
        "\n",
        " (94,\n",
        "  '0.050*\"сигнал\" + 0.028*\"частота\" + 0.018*\"звук\" + 0.012*\"мощность\" + 0.011*\"диапазон\" + 0.010*\"мм\" + 0.009*\"наушник\" + 0.009*\"лазер\" + 0.008*\"напряжение\" + 0.008*\"ток\"'),\n",
        "\n",
        "(5,\n",
        "  '0.027*\"яркость\" + 0.020*\"свет\" + 0.019*\"цвет\" + 0.012*\"диапазон\" + 0.011*\"красный\" + 0.009*\"координата\" + 0.009*\"цветок\" + 0.009*\"линейный\" + 0.008*\"цветовой\" + 0.008*\"кадр\"')\n",
        "\n",
        "Насколько я понимаю, хорошему качеству определения тем способствует увеличение параметров passes и num_topics. Попробуем в следующей попытке оставить passes=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqCTYplmkhF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda5 = gensim.models.LdaMulticore(corpus, id2word=dictionary, eval_every=1, num_topics=100, passes=1, alpha='asymmetric')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GVcHzpukiuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda5.print_topics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ4K_Xf0X3XX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "102d10c4-966d-4cfc-abe1-adf0ecc55a3b"
      },
      "source": [
        "lda5.log_perplexity(corpus[:10000])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-63.29175312654695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejc-fnMhm89D",
        "colab_type": "text"
      },
      "source": [
        "Всё ещё похоже на темы, но менее убедительно. Можно сделать вывод, что параметр passes действительно влияет на результат. Например, (1,\n",
        "  '0.010*\"int\" + 0.007*\"двигатель\" + 0.006*\"azure\" + 0.005*\"you\" + 0.004*\"предприятие\" + 0.004*\"ос\" + 0.003*\"lt\" + 0.003*\"подборка\" + 0.003*\"суд\" + 0.003*\"microsoft\"') - не очень похоже на тему. Теперь добавим tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4LzzccaIfY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = gensim.models.TfidfModel(corpus, id2word=dictionary)\n",
        "corpus = tfidf[corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgIpTTmkKwhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda4 = gensim.models.LdaMulticore(corpus, id2word=dictionary, eval_every=1, num_topics=100, passes=5, alpha='asymmetric')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR_KBaajrTVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda4.print_topics(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1wdngmLbFao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "cdf4fb60-e53c-4a74-f011-aac493198007"
      },
      "source": [
        "lda4.log_perplexity(corpus[:10000])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-11.858708434286587"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE7HZl_btHkH",
        "colab_type": "text"
      },
      "source": [
        "Применительно к модели, показавшей лучшие результаты, tdidf изменил их.  появились какие-то новые темы и результат скорее ухудшился. В лучшем случае 3-4 слова принадлежат какой-то общей теме. У многих слов показатель равен 0.000. Попробуем поменять параметры"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w5slSvJtwiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda2 = gensim.models.LdaMulticore(corpus, id2word=dictionary, eval_every=1, num_topics=20, passes=3, alpha='asymmetric')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gCavI20t3bL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda2.print_topics(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jaio-u0JbIti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "703117f9-7b89-4221-e962-d08c84cb518b"
      },
      "source": [
        "lda2.log_perplexity(corpus[:10000])"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-9.983256118158627"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf4i-Qt2ueLp",
        "colab_type": "text"
      },
      "source": [
        "Насколько я понимаю, частотность редких слов становится еще меньше. Это не очень сильно помогает с тематическим моделированием. Видимо, нужно подобрать другие параметры."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6835GLh2uxub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda3 = gensim.models.LdaMulticore(corpus, id2word=dictionary, eval_every=1, num_topics=10, passes=5, alpha='asymmetric')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsT80MNCu69S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "a89aa427-d562-42c4-c933-fb7689dfafb1"
      },
      "source": [
        "lda3.print_topics()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.001*\"•\" + 0.001*\"public\" + 0.001*\"игрок\" + 0.001*\"доклад\" + 0.001*\"инцидент\" + 0.001*\"заказчик\" + 0.001*\"мозг\" + 0.001*\"бот\" + 0.001*\"цифровой\" + 0.001*\"прибор\"'),\n",
              " (1,\n",
              "  '0.023*\"ия\" + 0.004*\"удовлетворение\" + 0.004*\"индивидуальный\" + 0.003*\"void\" + 0.003*\"public\" + 0.002*\"скорректировать\" + 0.002*\"прогнозировать\" + 0.002*\"true\" + 0.002*\"прогноз\" + 0.002*\"накопить\"'),\n",
              " (2,\n",
              "  '0.001*\"color\" + 0.000*\"рыба\" + 0.000*\"обмануть\" + 0.000*\"61\" + 0.000*\"бывший\" + 0.000*\"ibm\" + 0.000*\"тренд\" + 0.000*\"лидер\" + 0.000*\"unity\" + 0.000*\"доклад\"'),\n",
              " (3,\n",
              "  '0.000*\"compute\" + 0.000*\"card\" + 0.000*\"камера\" + 0.000*\"сетка\" + 0.000*\"unity\" + 0.000*\"наса\" + 0.000*\"рейтинг\" + 0.000*\"ide\" + 0.000*\"visual\" + 0.000*\"studio\"'),\n",
              " (4,\n",
              "  '0.000*\"ibm\" + 0.000*\"watson\" + 0.000*\"блокчейн\" + 0.000*\"датчик\" + 0.000*\"кандидат\" + 0.000*\"принтер\" + 0.000*\"iot\" + 0.000*\"наса\" + 0.000*\"вселенная\" + 0.000*\"когнитивный\"'),\n",
              " (5,\n",
              "  '0.000*\"вселенная\" + 0.000*\"•\" + 0.000*\"инфляция\" + 0.000*\"облачный\" + 0.000*\"crm\" + 0.000*\"кандидат\" + 0.000*\"нейрон\" + 0.000*\"наушник\" + 0.000*\"геном\" + 0.000*\"упаковка\"'),\n",
              " (6,\n",
              "  '0.000*\"стенд\" + 0.000*\"вредоносный\" + 0.000*\"кожа\" + 0.000*\"фильм\" + 0.000*\"css\" + 0.000*\"древние\" + 0.000*\"животное\" + 0.000*\"сердце\" + 0.000*\"клавиша\" + 0.000*\"горячее\"'),\n",
              " (7,\n",
              "  '0.000*\"ооо\" + 0.000*\"pid\" + 0.000*\"налог\" + 0.000*\"ндс\" + 0.000*\"oracle\" + 0.000*\"central\" + 0.000*\"sms\" + 0.000*\"мозг\" + 0.000*\"мужчина\" + 0.000*\"saas\"'),\n",
              " (8,\n",
              "  '0.000*\"галактика\" + 0.000*\"переехать\" + 0.000*\"робот\" + 0.000*\"звезда\" + 0.000*\"float\" + 0.000*\"излучение\" + 0.000*\"шейдёр\" + 0.000*\"char\" + 0.000*\"скан\" + 0.000*\"вселенная\"'),\n",
              " (9,\n",
              "  '0.000*\"ревить\" + 0.000*\"python\" + 0.000*\"дронов\" + 0.000*\"финал\" + 0.000*\"communications\" + 0.000*\"регистр\" + 0.000*\"cisco\" + 0.000*\"mov\" + 0.000*\"реле\" + 0.000*\"аэропорт\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPa4na5WvsvD",
        "colab_type": "text"
      },
      "source": [
        "Сравним некоторые полученные темы для модели с лучшими параметрами lda4 с tfidf и без него. \n",
        "Перплексия без tfidf - 11.763155684005355\n",
        "Перплексия с tfidf - -11.858708434286587 \n",
        "Разниц не сузественная. \n",
        "В модели с tfidf все темы поменялись кардинально (возможно, изменился их порядок, ведь мы выводим только 20 из 100). Во всех из них можно найти лишние слова. Например:\n",
        "(8,\n",
        "  '0.039*\"уязвимость\" + 0.038*\"англ\" + 0.033*\"apk\" + 0.029*\"вредоносный\" + 0.022*\"вирус\" + 0.017*\"android\" + 0.015*\"отчёт\" + 0.014*\"mb\" + 0.013*\"sms\" + 0.012*\"application\"'),\n",
        "  Есть какие-то общие темы, например: уязвимость, вредоносный, вирус. Но другие слова как-то не очень подходят.\n",
        "(98,\n",
        "  '0.000*\"бухгалтер\" + 0.000*\"1с\" + 0.000*\"android\" + 0.000*\"apk\" + 0.000*\"material\" + 0.000*\"скорректировать\" + 0.000*\"studio\" + 0.000*\"devices\" + 0.000*\"бекап\" + 0.000*\"нажимать\"')\n",
        "  Вроде бы есть бухгалтер и 1С, но насколько сюда подходят другие слова - сложно сказать\n",
        "  (2,\n",
        "  '0.007*\"laravel\" + 0.007*\"token\" + 0.007*\"заказчик\" + 0.006*\"загрузчик\" + 0.006*\"import\" + 0.006*\"датчик\" + 0.005*\"конвертация\" + 0.005*\"гибкость\" + 0.005*\"аудио\" + 0.005*\"прямоугольник\"'),\n",
        "  Сложно найти много общих слов\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Посмотрим на темы без tfidf\n",
        "\n",
        " (98,\n",
        "  '0.112*\"вакансия\" + 0.026*\"выборка\" + 0.026*\"навык\" + 0.017*\"москва\" + 0.016*\"рубль\" + 0.015*\"зарплата\" + 0.013*\"распределение\" + 0.012*\"профессиональный\" + 0.012*\"плата\" + 0.011*\"работодатель\"'),\n",
        " (96,\n",
        "  '0.054*\"матрица\" + 0.053*\"вектор\" + 0.033*\"кандидат\" + 0.027*\"диаграмма\" + 0.016*\"плагин\" + 0.015*\"угол\" + 0.013*\"метрика\" + 0.010*\"трансформация\" + 0.010*\"луч\" + 0.009*\"видимость\"'),\n",
        "\n",
        " (91,\n",
        "  '0.021*\"релиз\" + 0.019*\"скачать\" + 0.017*\"музыка\" + 0.017*\"стиль\" + 0.015*\"контент\" + 0.014*\"бот\" + 0.014*\"скачивание\" + 0.013*\"css\" + 0.011*\"протокол\" + 0.010*\"архив\"'),\n",
        "\n",
        " (6,\n",
        "  '0.037*\"sql\" + 0.031*\"error\" + 0.031*\"server\" + 0.022*\"code\" + 0.021*\"case\" + 0.020*\"бд\" + 0.017*\"public\" + 0.016*\"was\" + 0.015*\"var\" + 0.014*\"connection\"'),\n",
        " (3,\n",
        "  '0.064*\"температура\" + 0.048*\"питание\" + 0.048*\"корпус\" + 0.043*\"плата\" + 0.028*\"станция\" + 0.022*\"контроллер\" + 0.022*\"напряжение\" + 0.018*\"светодиод\" + 0.018*\"резистор\" + 0.017*\"датчик\"'),\n",
        " (2,\n",
        "  '0.038*\"доклад\" + 0.028*\"конференция\" + 0.011*\"net\" + 0.010*\"выступление\" + 0.009*\"2017\" + 0.008*\"microsoft\" + 0.008*\"спикер\" + 0.008*\"обсуждение\" + 0.007*\"фсб\" + 0.007*\"джон\"'),\n",
        "\n",
        "Между словами действительно можно построить какой-то ассоциативный ряд. Такие темы составляют более значительную долю. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioODIvg4yVCr",
        "colab_type": "text"
      },
      "source": [
        "NMF. Попробуем сразу изменить параметр max_features и max_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE2yVM__yIXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import NMF\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwTw22ETyfMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stexts = [' '.join(text) for text in texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLenHLoJy1Pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=100, min_df=10, max_df=0.1, ngram_range=(1,3))\n",
        "X = vectorizer.fit_transform(stexts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8DHcWYNzApe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = NMF(n_components=30) #пусть будет количество тем - 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh3m6TmFzIjy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "175c86f2-164a-4b6a-8180-12992660d8b5"
      },
      "source": [
        "model.fit(X)\n",
        "model.components_.shape\n",
        "model.transform(X).shape"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4121, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aibplr77zlxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_names = vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8rQHu5qziKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_words = model.components_.argsort()[:,:-5:-1]\n",
        "\n",
        "for i in range(top_words.shape[0]):\n",
        "    words = [feat_names[j] for j in top_words[i]]\n",
        "    print(i, \"  \".join(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfcwv7ko0oqY",
        "colab_type": "text"
      },
      "source": [
        "Что будет, если увеличить количество тем при тех же параметрах tfidf?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13eISHEF0ryP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = NMF(n_components=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OePwdUme1JK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X)\n",
        "model.components_.shape\n",
        "model.transform(X).shape\n",
        "feat_names = vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRWQLCSm1N6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_words = model.components_.argsort()[:,:-5:-1]\n",
        "\n",
        "for i in range(top_words.shape[0]):\n",
        "    words = [feat_names[j] for j in top_words[i]]\n",
        "    print(i, \"  \".join(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORPeqn1m1f1Q",
        "colab_type": "text"
      },
      "source": [
        "Вернемся к параметрам  tfidf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyeSD9Hw1kjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000, min_df=100, max_df=0.1, ngram_range=(1,3))\n",
        "X = vectorizer.fit_transform(stexts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK4sniyQ1xAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = NMF(n_components=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2rAZlKn1yu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X)\n",
        "model.components_.shape\n",
        "model.transform(X).shape\n",
        "feat_names = vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iH6t0H816ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_words = model.components_.argsort()[:,:-5:-1]\n",
        "\n",
        "for i in range(top_words.shape[0]):\n",
        "    words = [feat_names[j] for j in top_words[i]]\n",
        "    print(i, \"  \".join(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBONAi1C2T8l",
        "colab_type": "text"
      },
      "source": [
        "Выглядит лучше. Видимо, не стоило сильно уменьшать max_features. Попробуем снова увеличить количество тем"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3FSD6Aa2fy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = NMF(n_components=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpiC0-oY2iju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X)\n",
        "model.components_.shape\n",
        "model.transform(X).shape\n",
        "feat_names = vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZjN3p5d2k-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_words = model.components_.argsort()[:,:-5:-1]\n",
        "\n",
        "for i in range(top_words.shape[0]):\n",
        "    words = [feat_names[j] for j in top_words[i]]\n",
        "    print(i, \"  \".join(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcQqn2ZX2vnk",
        "colab_type": "text"
      },
      "source": [
        "Некоторые темы специфичны. Возможно 100 тем это слишком много для данной модели:\n",
        "конференция  2017  2017 год  международный; 00  встреча  декабрь  мероприятие\n",
        "\n",
        "Но в целом, картина хорошая. Часто все 4 слова действительно чем-то объединены:\n",
        "лекция  студент  университет  школа;\n",
        "энергия  солнечный  панель  мощность;\n",
        "температура  вода  воздух  прибор\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jDWcgvP36d8",
        "colab_type": "text"
      },
      "source": [
        "Итак, посмотрим на темы лучшей NMF модели и лучшей LDA модели.\n",
        "Количество тем разнится(в одной 30, а в другой 100). Возможно это не очень корректно для сравнения.  Некоторые темы вполне пересекаются. Буду выделять темы скобками. Например: 1) (94,'0.050*\"сигнал\" + 0.028*\"частота\" + 0.018*\"звук\" + 0.012*\"мощность\" + 0.011*\"диапазон\" + 0.010*\"мм\" + 0.009*\"наушник\" + 0.009*\"лазер\" + 0.008*\"напряжение\" + 0.008*\"ток\"') и ( сигнал  частота  напряжение  плата), 2) (95,'0.031*\"головка\" + 0.021*\"температура\" + 0.015*\"тепло\" + 0.014*\"расчёт\" + 0.014*\"робот\" + 0.014*\"печать\" + 0.009*\"пластик\" + 0.009*\"принтер\" + 0.008*\"предпочитать\" + 0.008*\"совет\"' )и (печать  3d  принтер  производство) \n",
        "Таким образом, можно сделать вывод, что результаты обеих моделей сопоставимы, однако в лучшей NMF меньше тем. Этот параметр опять же можно настроить лучше в обеих моделях. По сравнению с нграммной LDA NMF показала себя лучше. До этого по ошибке я рассматривал результаты LDA без нграммов и они показались лучше по качеству и сопоставимы с NMF. Ниже приведены полученные результаты по NMF и нграммной LDA. Еще ниже результаты по LDA без n-граммов. \n",
        "\n",
        "NMF:\n",
        "0 менеджер  профессиональный  заказчик  совет\n",
        "1 from  is  import  on\n",
        "2 учёный  мозг  клетка  пациент\n",
        "3 процессор  intel  гб  чип\n",
        "4 игрок  игровой  персонаж  реальность\n",
        "5 доклад  конференция  мероприятие  встреча\n",
        "6 public  void  string  private\n",
        "7 космический  спутник  орбита  аппарат\n",
        "8 linux  microsoft  ос  studio\n",
        "9 android  ios  apple  мобильный приложение\n",
        "10 атака  уязвимость  злоумышленник  пароль\n",
        "11 css  javascript  js  html\n",
        "12 int  amp  char  const\n",
        "13 облачный  облако  ibm  cloud\n",
        "14 печать  3d  принтер  производство\n",
        "15 дата центр  дата  вода  провайдер\n",
        "16 робот  ребёнок  датчик  интеллект\n",
        "17 gt  const  input  html\n",
        "18 бот  чат  facebook  url\n",
        "19 сигнал  частота  напряжение  плата\n",
        "20 звук  музыка  слушать  волна\n",
        "21 вселенная  энергия  звезда  теория\n",
        "22 автомобиль  дорога  метр  город\n",
        "23 камера  смартфон  аккумулятор  корпус\n",
        "24 var  function  true  let\n",
        "25 реклама  рубль  рекламный  доход\n",
        "26 товар  скидка  покупатель  покупка\n",
        "27 ip  трафик  домен  ip адрес\n",
        "28 диск  резервный  хранилище  ssd\n",
        "29 end  do  then  else\n",
        "\n",
        "LDA:\n",
        "\n",
        "\n",
        "[(99,\n",
        "  '0.027*\"хабра\" + 0.023*\"гипотеза\" + 0.012*\"linux\" + 0.012*\"город\" + 0.011*\"«вконтакте»\" + 0.010*\"оптимизация\" + 0.010*\"возраст\" + 0.010*\"сбор\" + 0.009*\"выборка\" + 0.009*\"r\"'),\n",
        " (98,\n",
        "  '0.112*\"вакансия\" + 0.026*\"выборка\" + 0.026*\"навык\" + 0.017*\"москва\" + 0.016*\"рубль\" + 0.015*\"зарплата\" + 0.013*\"распределение\" + 0.012*\"профессиональный\" + 0.012*\"плата\" + 0.011*\"работодатель\"'),\n",
        " (97,\n",
        "  '0.025*\"ex\" + 0.016*\"дизайнер\" + 0.015*\"офис\" + 0.012*\"крис\" + 0.010*\"unreal\" + 0.009*\"звук\" + 0.009*\"ведущий\" + 0.008*\"диалог\" + 0.008*\"glass\" + 0.008*\"тестовый\"'),\n",
        " (96,\n",
        "  '0.054*\"матрица\" + 0.053*\"вектор\" + 0.033*\"кандидат\" + 0.027*\"диаграмма\" + 0.016*\"плагин\" + 0.015*\"угол\" + 0.013*\"метрика\" + 0.010*\"трансформация\" + 0.010*\"луч\" + 0.009*\"видимость\"'),\n",
        " (94,\n",
        "  '0.050*\"сигнал\" + 0.028*\"частота\" + 0.018*\"звук\" + 0.012*\"мощность\" + 0.011*\"диапазон\" + 0.010*\"мм\" + 0.009*\"наушник\" + 0.009*\"лазер\" + 0.008*\"напряжение\" + 0.008*\"ток\"'),\n",
        " (95,\n",
        "  '0.031*\"головка\" + 0.021*\"температура\" + 0.015*\"тепло\" + 0.014*\"расчёт\" + 0.014*\"робот\" + 0.014*\"печать\" + 0.009*\"пластик\" + 0.009*\"принтер\" + 0.008*\"предпочитать\" + 0.008*\"совет\"'),\n",
        " (93,\n",
        "  '0.046*\"стикер\" + 0.030*\"граница\" + 0.026*\"цифровой\" + 0.026*\"выделение\" + 0.025*\"доска\" + 0.015*\"цвет\" + 0.013*\"цвета\" + 0.012*\"социальный\" + 0.012*\"прямоугольник\" + 0.012*\"фон\"'),\n",
        " (92,\n",
        "  '0.099*\"раздел\" + 0.050*\"пароль\" + 0.040*\"папка\" + 0.032*\"шифрование\" + 0.027*\"ввести\" + 0.024*\"зашифровать\" + 0.019*\"флешек\" + 0.018*\"окно\" + 0.018*\"случайный\" + 0.014*\"терминал\"'),\n",
        " (91,\n",
        "  '0.021*\"релиз\" + 0.019*\"скачать\" + 0.017*\"музыка\" + 0.017*\"стиль\" + 0.015*\"контент\" + 0.014*\"бот\" + 0.014*\"скачивание\" + 0.013*\"css\" + 0.011*\"протокол\" + 0.010*\"архив\"'),\n",
        " (90,\n",
        "  '0.101*\"34\" + 0.066*\"28\" + 0.064*\"define\" + 0.053*\"amp;&amp\" + 0.040*\"output\" + 0.040*\"32\" + 0.029*\"реле\" + 0.028*\"high\" + 0.021*\"62\" + 0.020*\"low\"'),\n",
        " (9,\n",
        "  '0.065*\"b\" + 0.041*\"int\" + 0.033*\"d\" + 0.029*\"e\" + 0.027*\"float\" + 0.024*\"long\" + 0.022*\"j\" + 0.020*\"lt\" + 0.016*\"n\" + 0.014*\"amp;&amp\"'),\n",
        " (8,\n",
        "  '0.037*\"станция\" + 0.037*\"→\" + 0.026*\"sip\" + 0.020*\"ip\" + 0.019*\"address\" + 0.019*\"нажимать\" + 0.018*\"абонент\" + 0.016*\"подсеть\" + 0.016*\"asterisk\" + 0.014*\"system\"'),\n",
        " (7,\n",
        "  '0.074*\"токен\" + 0.043*\"индекс\" + 0.034*\"подсветка\" + 0.033*\"иванов\" + 0.031*\"иван\" + 0.027*\"мб\" + 0.026*\"формирование\" + 0.024*\"мс\" + 0.021*\"предложение\" + 0.020*\"фраза\"'),\n",
        " (6,\n",
        "  '0.037*\"sql\" + 0.031*\"error\" + 0.031*\"server\" + 0.022*\"code\" + 0.021*\"case\" + 0.020*\"бд\" + 0.017*\"public\" + 0.016*\"was\" + 0.015*\"var\" + 0.014*\"connection\"'),\n",
        " (5,\n",
        "  '0.027*\"яркость\" + 0.020*\"свет\" + 0.019*\"цвет\" + 0.012*\"диапазон\" + 0.011*\"красный\" + 0.009*\"координата\" + 0.009*\"цветок\" + 0.009*\"линейный\" + 0.008*\"цветовой\" + 0.008*\"кадр\"'),\n",
        " (4,\n",
        "  '0.029*\"uber\" + 0.024*\"view\" + 0.023*\"бизнес-логика\" + 0.019*\"поездка\" + 0.018*\"mvc\" + 0.016*\"product\" + 0.015*\"router\" + 0.013*\"дерево\" + 0.013*\"автомобиль\" + 0.012*\"паттерн\"'),\n",
        " (3,\n",
        "  '0.064*\"температура\" + 0.048*\"питание\" + 0.048*\"корпус\" + 0.043*\"плата\" + 0.028*\"станция\" + 0.022*\"контроллер\" + 0.022*\"напряжение\" + 0.018*\"светодиод\" + 0.018*\"резистор\" + 0.017*\"датчик\"'),\n",
        " (2,\n",
        "  '0.038*\"доклад\" + 0.028*\"конференция\" + 0.011*\"net\" + 0.010*\"выступление\" + 0.009*\"2017\" + 0.008*\"microsoft\" + 0.008*\"спикер\" + 0.008*\"обсуждение\" + 0.007*\"фсб\" + 0.007*\"джон\"'),\n",
        " (1,\n",
        "  '0.032*\"java\" + 0.018*\"фильтр\" + 0.015*\"инженер\" + 0.014*\"советский\" + 0.013*\"звук\" + 0.013*\"производство\" + 0.012*\"создатель\" + 0.008*\"куча\" + 0.008*\"усилитель\" + 0.008*\"серия\"'),\n",
        " (0,\n",
        "  '0.013*\"amazon\" + 0.012*\"loss\" + 0.008*\"контроллер\" + 0.008*\"дисплей\" + 0.007*\"gpu\" + 0.007*\"git\" + 0.006*\"текстура\" + 0.005*\"make\" + 0.005*\"lenovo\" + 0.005*\"шина\"')]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "LDA без n-граммов\n",
        "\n",
        "(99,\n",
        "  '0.072*\"товар\" + 0.047*\"amazon\" + 0.040*\"доставка\" + 0.035*\"магазин\" + 0.030*\"покупка\" + 0.024*\"покупатель\" + 0.019*\"потребитель\" + 0.019*\"аккаунт\" + 0.014*\"ветка\" + 0.012*\"продавец\"'),\n",
        " (98,\n",
        "  '0.015*\"окно\" + 0.013*\"меню\" + 0.012*\"панель\" + 0.010*\"xml\" + 0.009*\"редактор\" + 0.007*\"1с\" + 0.007*\"график\" + 0.007*\"диаграмма\" + 0.007*\"анимация\" + 0.007*\"watson\"'),\n",
        " (97,\n",
        "  '0.052*\"клетка\" + 0.022*\"ген\" + 0.020*\"образование\" + 0.019*\"ребёнок\" + 0.018*\"тело\" + 0.015*\"женщина\" + 0.014*\"болезнь\" + 0.013*\"заболевание\" + 0.011*\"организм\" + 0.011*\"пациент\"'),\n",
        " (96,\n",
        "  '0.014*\"is\" + 0.014*\"system\" + 0.009*\"on\" + 0.009*\"boot\" + 0.009*\"show\" + 0.009*\"version\" + 0.009*\"laravel\" + 0.008*\"master\" + 0.008*\"use\" + 0.008*\"device\"'),\n",
        " (95,\n",
        "  '0.077*\"батарея\" + 0.074*\"tesla\" + 0.067*\"аккумулятор\" + 0.052*\"ёмкость\" + 0.036*\"ячейка\" + 0.031*\"производство\" + 0.028*\"model\" + 0.028*\"охлаждение\" + 0.018*\"напряжение\" + 0.016*\"заявить\"'),\n",
        " (93,\n",
        "  '0.053*\"китай\" + 0.038*\"цифровой\" + 0.031*\"правительство\" + 0.029*\"китайский\" + 0.024*\"блокировка\" + 0.024*\"провайдер\" + 0.021*\"социальный\" + 0.021*\"vpn\" + 0.015*\"корпоративный\" + 0.013*\"зарубежный\"'),\n",
        " (94,\n",
        "  '0.045*\"статический\" + 0.039*\"android\" + 0.033*\"динамический\" + 0.030*\"иконка\" + 0.025*\"короткий\" + 0.016*\"удалять\" + 0.015*\"•\" + 0.015*\"отображаться\" + 0.014*\"длинный\" + 0.014*\"удаление\"'),\n",
        " (92,\n",
        "  '0.020*\"камера\" + 0.018*\"смартфон\" + 0.008*\"гб\" + 0.008*\"ноутбук\" + 0.007*\"дисплей\" + 0.007*\"разрешение\" + 0.006*\"процессор\" + 0.006*\"корпус\" + 0.006*\"видеокарта\" + 0.005*\"рубль\"'),\n",
        " (91,\n",
        "  '0.044*\"космический\" + 0.040*\"земля\" + 0.036*\"орбита\" + 0.034*\"аппарат\" + 0.033*\"спутник\" + 0.028*\"полёт\" + 0.026*\"луна\" + 0.025*\"марс\" + 0.019*\"наса\" + 0.018*\"ракета\"'),\n",
        " (90,\n",
        "  '0.032*\"диск\" + 0.023*\"ssd\" + 0.019*\"накопитель\" + 0.018*\"скидка\" + 0.015*\"драйвер\" + 0.015*\"блокчейн\" + 0.012*\"операционный\" + 0.012*\"финансовый\" + 0.009*\"файловый\" + 0.009*\"платёж\"'),\n",
        " (9,\n",
        "  '0.008*\"тестовый\" + 0.007*\"crm\" + 0.007*\"менеджер\" + 0.006*\"функционал\" + 0.006*\"планирование\" + 0.006*\"внедрение\" + 0.006*\"автоматизация\" + 0.006*\"git\" + 0.005*\"баг\" + 0.004*\"релиз\"'),\n",
        " (8,\n",
        "  '0.046*\"контейнер\" + 0.023*\"сборка\" + 0.020*\"docker\" + 0.017*\"консоль\" + 0.016*\"linux\" + 0.015*\"run\" + 0.012*\"nginx\" + 0.012*\"d\" + 0.012*\"каталог\" + 0.010*\"папка\"'),\n",
        " (7,\n",
        "  '0.093*\"ms\" + 0.047*\"sec\" + 0.028*\"00\" + 0.026*\"sum\" + 0.023*\"oracle\" + 0.018*\"person\" + 0.013*\"sap\" + 0.012*\"bytes\" + 0.010*\"акция\" + 0.010*\"handle\"'),\n",
        " (6,\n",
        "  '0.037*\"двигатель\" + 0.025*\"квеста\" + 0.023*\"загадка\" + 0.018*\"город\" + 0.017*\"зона\" + 0.016*\"производство\" + 0.015*\"партнёр\" + 0.012*\"электроника\" + 0.010*\"плата\" + 0.010*\"пуск\"'),\n",
        " (5,\n",
        "  '0.028*\"раздел\" + 0.022*\"цифровой\" + 0.014*\"токен\" + 0.010*\"распространение\" + 0.009*\"свободный\" + 0.007*\"зашифровать\" + 0.007*\"ввести\" + 0.007*\"иван\" + 0.007*\"иванов\" + 0.007*\"предметный\"'),\n",
        " (4,\n",
        "  '0.037*\"err\" + 0.034*\"функциональный\" + 0.033*\"var\" + 0.028*\"function\" + 0.028*\"error\" + 0.026*\"const\" + 0.023*\"rate\" + 0.023*\"res\" + 0.022*\"javascript\" + 0.020*\"user\"'),\n",
        " (3,\n",
        "  '0.012*\"сигнал\" + 0.011*\"протокол\" + 0.009*\"трафик\" + 0.008*\"частота\" + 0.007*\"маршрут\" + 0.007*\"сетевой\" + 0.006*\"маршрутизатор\" + 0.006*\"соединение\" + 0.004*\"сессия\" + 0.003*\"tcp\"'),\n",
        " (2,\n",
        "  '0.034*\"linux\" + 0.018*\"http\" + 0.017*\"оптимизация\" + 0.017*\"серверный\" + 0.016*\"балансировка\" + 0.014*\"кэширование\" + 0.013*\"сжатие\" + 0.013*\"проксить\" + 0.013*\"доход\" + 0.013*\"налог\"'),\n",
        " (1,\n",
        "  '0.023*\"нативный\" + 0.023*\"контент\" + 0.019*\"веб\" + 0.015*\"facebook\" + 0.014*\"ios\" + 0.013*\"бот\" + 0.012*\"мессенджер\" + 0.011*\"социальный\" + 0.010*\"операционный\" + 0.010*\"предпочитать\"'),\n",
        " (0,\n",
        "  '0.023*\"массив\" + 0.023*\"b\" + 0.020*\"const\" + 0.018*\"int\" + 0.017*\"n\" + 0.014*\"y\" + 0.013*\"lt\" + 0.011*\"p\" + 0.010*\"указатель\" + 0.009*\"json\"')"
      ]
    }
  ]
}