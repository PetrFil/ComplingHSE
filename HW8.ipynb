{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IEEaSpJl7Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7R5ktKi-5FN",
        "colab_type": "code",
        "outputId": "e41d3487-2172-43e2-ac5a-e077cef27fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSZlBBpz-7HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json, os\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KyV32UVa224",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from string import punctuation\n",
        "punct = punctuation+'«»—…“”*№–'\n",
        "stops = set(stopwords.words('russian'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaaWBuXu--8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_colwidth', 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-kmH6DMV8wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGfyR6cP_5gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_DATA = '/gdrive/My Drive/data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtaigPSm_6QF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = [os.path.join(PATH_TO_DATA, file) for file in os.listdir(PATH_TO_DATA)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaB-HarQACBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.concat([pd.read_json(file, lines=True) for file in files], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6qcxmp0W7_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(true_kws, predicted_kws):\n",
        "    assert len(true_kws) == len(predicted_kws)\n",
        "    \n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1s = []\n",
        "    jaccards = []\n",
        "    \n",
        "    for i in range(len(true_kws)):\n",
        "        true_kw = set(true_kws[i])\n",
        "        predicted_kw = set(predicted_kws[i])\n",
        "        \n",
        "        tp = len(true_kw & predicted_kw)\n",
        "        union = len(true_kw | predicted_kw)\n",
        "        fp = len(predicted_kw - true_kw)\n",
        "        fn = len(true_kw - predicted_kw)\n",
        "        \n",
        "        if (tp+fp) == 0:\n",
        "            prec = 0\n",
        "        else:\n",
        "            prec = tp / (tp + fp)\n",
        "        \n",
        "        if (tp+fn) == 0:\n",
        "            rec = 0\n",
        "        else:\n",
        "            rec = tp / (tp + fn)\n",
        "        if (prec+rec) == 0:\n",
        "            f1 = 0\n",
        "        else:\n",
        "            f1 = (2*(prec*rec))/(prec+rec)\n",
        "            \n",
        "        jac = tp / union\n",
        "        \n",
        "        precisions.append(prec)\n",
        "        recalls.append(rec)\n",
        "        f1s.append(f1)\n",
        "        jaccards.append(jac)\n",
        "    print('Precision - ', round(np.mean(precisions), 2))\n",
        "    print('Recall - ', round(np.mean(recalls), 2))\n",
        "    print('F1 - ', round(np.mean(f1s), 2))\n",
        "    print('Jaccard - ', round(np.mean(jaccards), 2))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScTUcU51bCya",
        "colab_type": "text"
      },
      "source": [
        "###Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwLu73qocDd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text): # без pymorphy\n",
        "    \n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "    words = [word for word in words if word not in stops]\n",
        "\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT2LqeL4e5rL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['content_norm'] = data['content'].apply(normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBuT6pL2f8t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['content_norm_str'] = data['content_norm'].apply(' '.join)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncg7B8BwgRv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99VBVwwNgTdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf.fit(data['content_norm_str'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D-62oqkgV_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJcFSyGEgg_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_vectors = tfidf.transform(data['content_norm_str'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ5KZ8LvkPj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keywords = []\n",
        "\n",
        "for row in range(texts_vectors.shape[0]):\n",
        "    row_data = texts_vectors.getrow(row)\n",
        "    top_inds = row_data.toarray().argsort()[0,:-11:-1]\n",
        "    keywords.append([id2word[w] for w in top_inds])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afxyX2BIkhoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keywords[:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbunXBm6g2AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate(data['keywords'], keywords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE0arRnupY--",
        "colab_type": "text"
      },
      "source": [
        "Результат сильно хуже того, что был на семинаре. Поэтому попробуем применить pymorphy хотя бы к полученным ключевым словам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GeltTwop_x-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm_words(words):\n",
        "  normalized = []\n",
        "  for wordlist in words:\n",
        "    normal = [morph.parse(word)[0].normal_form for word in wordlist]\n",
        "    normalized += [normal] \n",
        "  return normalized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDckg3OPqm2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_keywords = norm_words(keywords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWsR5xuSni7w",
        "colab_type": "code",
        "outputId": "f8f722e9-2926-443f-a810-3b38695ac789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "evaluate(data['keywords'], norm_keywords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.08\n",
            "Recall -  0.11\n",
            "F1 -  0.09\n",
            "Jaccard -  0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VN3xpDFpu_c",
        "colab_type": "text"
      },
      "source": [
        "### Способ 1. Поменяем параметры tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnS-b8AfrHKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = TfidfVectorizer(min_df=2, max_df=0.5) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI_UWv7QsHfQ",
        "colab_type": "code",
        "outputId": "f466061e-31b5-4093-ecf9-f02826b88f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "tfidf.fit(data['content_norm_str'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=0.5, max_features=None,\n",
              "                min_df=2, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjeEFmxivEWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNIOWYGWvITF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_vectors = tfidf.transform(data['content_norm_str'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ajlnIyvPAf",
        "colab_type": "code",
        "outputId": "b078247a-d7b7-4185-e6a1-d5b95d5e085d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%%time\n",
        "keywords = []\n",
        "\n",
        "for row in range(texts_vectors.shape[0]):\n",
        "    row_data = texts_vectors.getrow(row)\n",
        "    top_inds = row_data.toarray().argsort()[0,:-11:-1]\n",
        "    keywords.append([id2word[w] for w in top_inds])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 57s, sys: 911 ms, total: 2min 58s\n",
            "Wall time: 2min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M41Rm6cvTtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_keywords = norm_words(keywords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm_PjJqos03A",
        "colab_type": "code",
        "outputId": "e7a2dccc-3f74-4b50-e472-0ff36607db9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "evaluate(data['keywords'], norm_keywords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.09\n",
            "Recall -  0.12\n",
            "F1 -  0.1\n",
            "Jaccard -  0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip0VHxHq4WOh",
        "colab_type": "text"
      },
      "source": [
        "Были опробованы различные параметры mindf, maxdf, ngram_range. Результат в некоторых случаях незначительно улучшался(как в примере выше)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAyx3d3d8DC2",
        "colab_type": "text"
      },
      "source": [
        "###Способ 2. Положение ключевых слов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osJE7UKU8QOf",
        "colab_type": "text"
      },
      "source": [
        "Нередко в новостных статьях основная мысль озвучивается в первом предложении. Предположим, что ключевые слова чаще всего встречаются именно там"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMnU1eCe7-zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_sent=data['content'].apply(lambda x: x.split('.')[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJUgWJWl9Sij",
        "colab_type": "code",
        "outputId": "24eee7d7-0876-42c1-baa3-e15019aaefd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "first_sent.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                  Действия России, якобы совершившей кибератаки на избирательную комиссию штата Иллинойс в июле 2016 года, должны быть осуждены США\n",
              "1                                           Президент Латвии Раймонд Вейонис предлагает предоставлять всем детям русскоязычных неграждан латвийское гражданство сразу после рождения\n",
              "2         Совет Безопасности ООН единогласно принял резолюцию 2401, которая требует от всех сторон конфликта в Сирии безотлагательно остановить боевые действия на территории страны\n",
              "3                                   Выиграть главный футбольный матч клубного сезона Европы в одиночку невозможно, даже если ты являешься одним из лучших футбольных вратарей в мире\n",
              "4    Украинским военным стоит быть весьма бдительными, если они всё-таки решат забрать свою технику из Крыма, — ведь Россия вполне может «заминировать корабли», подлежащие передаче\n",
              "Name: content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNPeV8Ig-MAw",
        "colab_type": "text"
      },
      "source": [
        "Используем функцию normalize из семинарской тетрадки с удалением стоп-слов и несуществительных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0zMjJxu-J2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    \n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "    words = [morph.parse(word)[0] for word in words if word and word not in stops]\n",
        "    words = [word.normal_form for word in words if word.tag.POS == 'NOUN']\n",
        "\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGw5hAma-T7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_sent = first_sent.apply(lambda x: normalize(x)[:10]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEVK4rJw-p_N",
        "colab_type": "code",
        "outputId": "819bc8d6-de88-4d2c-a5b3-3c19afd5a2f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "first_sent.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                         [действие, россия, кибератака, комиссия, штат, иллинойс, июль, год, сша]\n",
              "1               [президент, латвия, раймонд, вейонис, ребёнок, негражданин, гражданство, рождение]\n",
              "2    [совет, безопасность, оон, резолюция, сторона, конфликт, сирия, действие, территория, страна]\n",
              "3                                                    [матч, сезон, европа, одиночка, вратарь, мир]\n",
              "4                                  [военный, техника, крым, россия, корабль, подлежащее, передача]\n",
              "Name: content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSiolwjZ-jsp",
        "colab_type": "code",
        "outputId": "d080aa89-0131-4584-e0ef-43bd78b4f8eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "evaluate(data['keywords'], first_sent)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.07\n",
            "Recall -  0.07\n",
            "F1 -  0.06\n",
            "Jaccard -  0.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2kWlH3i78nl",
        "colab_type": "text"
      },
      "source": [
        "Результат ухудшился. Однако, на мой взгляд, всё равно он не так уж и плох, учитывая, что в бейзлайне мы анализируем слова во всем тексте, а здесь - берем их только из первого предложения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trVOIAp_oj4R",
        "colab_type": "text"
      },
      "source": [
        "### Способ 3. Графы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzuOGlBCInfZ",
        "colab_type": "text"
      },
      "source": [
        "Начнем с тех параметров, которые были на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1RlUIoix3fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_kws(text, top=5, window_size=5, random_p=0.1):\n",
        "\n",
        "    vocab = set(text)\n",
        "    word2id = {w:i for i, w in enumerate(vocab)}\n",
        "    id2word = {i:w for i, w in enumerate(vocab)}\n",
        "    ids = [word2id[word] for word in text]\n",
        "\n",
        "    m = np.zeros((len(vocab), len(vocab)))\n",
        "\n",
        "    for i in range(0, len(ids), window_size):\n",
        "        window = ids[i:i+window_size]\n",
        "        for j, k in combinations(window, 2):\n",
        "            m[j][k] += 1\n",
        "            m[k][j] += 1\n",
        "    \n",
        "    for i in range(m.shape[0]):\n",
        "        s = np.sum(m[i])\n",
        "        if not s:\n",
        "            continue\n",
        "        m[i] /= s\n",
        "\n",
        "    c = Counter()\n",
        "    n = np.random.choice(len(vocab))\n",
        "    for i in range(500): \n",
        "\n",
        "        go_random = np.random.choice([0, 1], p=[1-random_p, random_p])\n",
        "        if go_random:\n",
        "            n = np.random.choice(len(vocab))\n",
        "        \n",
        "        n = take_step(n, m)\n",
        "        c.update([n])\n",
        "    \n",
        "    return [id2word[i] for i, count in c.most_common(top)]\n",
        "\n",
        "def take_step(n, matrix):\n",
        "    rang = len(matrix[n])\n",
        "    if np.any(matrix[n]):\n",
        "        next_n = np.random.choice(range(rang), p=matrix[n])\n",
        "    else:\n",
        "        next_n = np.random.choice(range(rang))\n",
        "    return next_n\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIVbApF8gscK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# по какой-то причине 4 статьи были без текста и из-за них всё ломалось\n",
        "# здесь я их вычислил\n",
        "i = 0\n",
        "for element in data['content_norm']:\n",
        "  if len(element)==0:\n",
        "    print(i)\n",
        "  i+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtF4flLBI53-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop([11538, 12728, 12800, 14535]) # удаление пустых текстов"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2V7x9Z5s7rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind = [i for i in range(len(data['keywords']))]\n",
        "data = data.set_index(pd.Index(ind)) # меняем индексы, чтобы они были по порядку и evaluate работал"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YOJa8C4OVNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c7d7c9bf-4184-4bce-9cfe-6a49b9b56968"
      },
      "source": [
        "%%time\n",
        "keywords_rw = data['content_norm'].apply(lambda x: get_kws(x, 10, 10))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 28min 3s, sys: 16.3 s, total: 28min 19s\n",
            "Wall time: 28min 20s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P-Bls3ID_aP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_keywords = norm_words(keywords_rw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBqIAGuuDEoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind = [i for i in range(len(data['keywords']))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukOb3_SMGiaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.set_index(pd.Index(ind))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF1ml9RB2DFx",
        "colab_type": "code",
        "outputId": "1209ab55-2d02-42cb-fa82-d081d5346647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "evaluate(data['keywords'], norm_keywords)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.06\n",
            "Recall -  0.08\n",
            "F1 -  0.06\n",
            "Jaccard -  0.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogRQBBZbJOD-",
        "colab_type": "text"
      },
      "source": [
        "Получилось хуже бейзлайна"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytzV7GPkJAnk",
        "colab_type": "text"
      },
      "source": [
        "Попробуем задать другие параметры. Сделаем окно - 2 слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqERYMUnGQL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keywords_rw = data['content_norm'].apply(lambda x: get_kws(x, 10, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCSBKaD3JHsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_keywords = norm_words(keywords_rw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0tQ3y4TJKA-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "301cde99-13c7-4d47-ce53-e47c4e0b8e52"
      },
      "source": [
        "evaluate(data['keywords'], norm_keywords)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.02\n",
            "Recall -  0.03\n",
            "F1 -  0.02\n",
            "Jaccard -  0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR80f5spNzIZ",
        "colab_type": "text"
      },
      "source": [
        "окно - 6 слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghVMmMA5N19L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "718a4314-7110-4eb7-804a-671c0d298091"
      },
      "source": [
        "%%time\n",
        "keywords_rw = data['content_norm'].apply(lambda x: get_kws(x, 10, 2))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 26min 28s, sys: 12.3 s, total: 26min 41s\n",
            "Wall time: 26min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsVjzowIN3aX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_keywords = norm_words(keywords_rw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIbOREPVN68Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "6c74f965-815a-4e03-b7b6-690f3663b917"
      },
      "source": [
        "evaluate(data['keywords'], norm_keywords)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.02\n",
            "Recall -  0.03\n",
            "F1 -  0.02\n",
            "Jaccard -  0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF8Z40I-P4ZI",
        "colab_type": "text"
      },
      "source": [
        "Выводы:\n",
        "1) Изменение параметров tfidf может улучшить результат\n",
        "2) Положение слов в тексте действительно может играть роль при извлечении ключевых слов, но при этом важно учитывать специфику текста\n",
        "3) Графы могут показать неплохой результат, важен правильный подбор параметров\n",
        "4) Бейзлайн был незначительно побит только изменением параметров tfidf\n",
        "5) К сожалению, не хватило времени и ресурсов на лемматизацию основного текста при помощи pymorphy2. Судя по семинару, это могло бы сильно улучшить результат (но датасет там был поменьше)"
      ]
    }
  ]
}