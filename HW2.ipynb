{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Биграммная модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/PetrFil/ComplingHSE/master/A.txt\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def ngrammer(tokens, n=2):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams\n",
    "def normalize(text):\n",
    "    normalized_text = [word.strip(punctuation) for word in text.lower().split()]\n",
    "    normalized_text = [word for word in normalized_text if word]\n",
    "    return normalized_text\n",
    "def generate(matrix, id2word, word2id, n=100, start='<start>'):\n",
    "    text = []\n",
    "    current_idx = word2id[start]\n",
    "    for i in range(n): \n",
    "      chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
    "      text.append(id2word[chosen])\n",
    "      if id2word[chosen] == '<end>':\n",
    "            chosen = word2id['<start>']\n",
    "      current_idx = chosen\n",
    "    return ' '.join(text)\n",
    "coelho = open('A.txt', encoding = 'utf-8').read()\n",
    "norm_coelho = normalize(coelho)\n",
    "vocab_coelho = Counter(norm_coelho)\n",
    "probas_coelho = Counter({word:c/len(norm_coelho) for word, c in vocab_coelho.items()})\n",
    "sentences_coelho = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(coelho)]\n",
    "unigrams_coelho = Counter()\n",
    "bigrams_coelho = Counter()\n",
    "for sentence in sentences_coelho:\n",
    "    unigrams_coelho.update(sentence)\n",
    "    bigrams_coelho.update(ngrammer(sentence))\n",
    "matrix_coelho= np.zeros((len(unigrams_coelho), len(unigrams_coelho)))\n",
    "id2word_coelho = list(unigrams_coelho)\n",
    "word2id_coelho = {word:i for i, word in enumerate(id2word_coelho)}\n",
    "for ngram in bigrams_coelho:\n",
    "  word1, word2 = ngram.split()\n",
    "  matrix_coelho[word2id_coelho[word1]][word2id_coelho[word2]] =  (bigrams_coelho[ngram]/unigrams_coelho[word1])\n",
    "print(generate(matrix_coelho, id2word_coelho, word2id_coelho).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты:\n",
    "кто живет своей личной легенды как превратить меня также сказал он сунул руку к его слезы был еще там жили только два года с соколом на тротуаре с ней остальная часть твоей личной легенде он две ночи пустыни и философских исследований \n",
    
    " он уже заметил» ответил \n",
    
    " он заметил что заставляет меня нет усталости \n",
    
    " «они рок-кристаллы не знали как все что заставил мальчика англичанин философский камень превращает любой ценой \n",
    
    " его дюны его песками \n",
    
    " «вот сказал мальчик не знал что люди знали город включая место без падения \n",
    
    " «действительно жизнь которая сделала \n",
    
    " в этой планете есть жизнь»\n",
    
    "    была большая горизонты которые написаны нет у животных и он свободно отпускал лошадь \n",
    
    " мальчик \n",
    
    " сеньон был враг будет память \n",
    
    " «но прежде он разбудил одного вся вселенная сжимается чтобы продать l «это пройдет» сказал я прихожу \n",
    
    " молодой араб \n",
    
    " не пожалел английского верблюда и следовать знамениям» сказал ему что выглядело как будто пустыня это была пустыня могла бы ни слова с любовь с его воинов \n",
    
    " он положил немного денег если они такие как продолжить его уважать его спутник \n",
    
    " он начал петь пока говорил с деньги никто не делать \n",
    
    " но вы состаритесь вы следовали за"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Триграммная модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/PetrFil/ComplingHSE/master/A.txt\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def ngrammer(tokens, n):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams\n",
    "def normalize(text):\n",
    "    normalized_text = [word.strip(punctuation) for word in text.lower().split()]\n",
    "    normalized_text = [word for word in normalized_text if word]\n",
    "    return normalized_text\n",
    "def generate(matrix, id2word, bigram2id, n=100, start='<start> <start>'):\n",
    "    text = []\n",
    "    current_idx = bigram2id[start]\n",
    "    next_bigram = start.split()\n",
    "    for i in range(n): \n",
    "      chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
    "      text.append(id2word[chosen])\n",
    "      if id2word[chosen] == '<end>':\n",
    "        next_bigram = start.split()\n",
    "        current_idx = bigram2id[start]\n",
    "        continue\n",
    "      next_bigram.remove(next_bigram[0])\n",
    "      next_bigram += [id2word[chosen]]\n",
    "      current_idx = bigram2id[next_bigram[0] + ' ' + next_bigram[1]]\n",
    "    return ' '.join(text)\n",
    "coelho = open('A.txt', encoding = 'utf-8').read()\n",
    "sentences_coelho = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(coelho)]\n",
    "unigrams_coelho = Counter()\n",
    "bigrams_coelho = Counter()\n",
    "trigrams_coelho = Counter()\n",
    "for sentence in sentences_coelho:\n",
    "    unigrams_coelho.update(sentence)\n",
    "    bigrams_coelho.update(ngrammer(sentence, 2))\n",
    "    trigrams_coelho.update(ngrammer(sentence, 3))\n",
    "matrix_coelho= np.zeros((len(bigrams_coelho), len(unigrams_coelho)))\n",
    "id2word_coelho = list(unigrams_coelho)\n",
    "word2id_coelho = {word:i for i, word in enumerate(id2word_coelho)}\n",
    "id2bigram_coelho = list(bigrams_coelho)\n",
    "bigram2id_coelho = {bigram:i for i, bigram in enumerate(id2bigram_coelho)}\n",
    "for ngram in trigrams_coelho:\n",
    "  word1, word2, word3 = ngram.split()\n",
    "  bigram = '{} {}'.format(word1, word2)\n",
    "  matrix_coelho[bigram2id_coelho[bigram]][word2id_coelho[word3]] =  (trigrams_coelho[ngram]/bigrams_coelho[bigram])\n",
    "print(generate(matrix_coelho, id2word_coelho, bigram2id_coelho).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты:\n",
    "эпоха толстая книга в которой говорится «что бы ни настаивал английский \n",
    
    " он сунул руку в седельную сумку и собирал один из начальников глядя на девушку \n",
    
    " гораздо лучше чем другие потому что женщина в пустыне даже понимая язык мира без объяснения причин потому что ветры всегда знают все \n",
    
    " он вспомнил ночь в пустыне пытаясь выслушать тщательно что его лошадь была какой следующий удар он должен был сдаться \n",
    
    " мальчик открыл глаза когда солнце стало сильнее и они поговорили с одним человеком говорящим по-арабски а другой говорящим по-испански \n",
   
    " «я плачу о нарциссе но я не поеду в мекку\n",
  
    "    и я учу тебя доберитесь до скрытого сокровища \n",
    
    " «я среди овец и убить его \n",
   
    " й чтобы проникнуть в душу мира которая сделана из песка а животных их поводья \n",
    
    " и если бы он всю жизнь \n",
    
    " и они не получить их \n",
   
    " молодой человек обнаружил что человек предал меня \n",
    
    " «следуйте за пирамидами» сказал алхимик \n",
    
    " «здесь много людей продают чай ответил торговец \n",
    
    " мальчик начал смотреть на горизонт впереди него \n",
   
    " и твердая часть была слоем философского камня \n",
   
    " потому что в магазине было знаком и как будто время остановилось и появилась душа мира и увидел что"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, текст, полученный с помощью второй модели выглядит более связным. В случае с биграммной моделью зачастую отсутствует согласование \"кто живет своей личной легенды\", \"сунул руку к его слезы\",  \"остальная часть твоей личной легенде\", \"пока говорил с деньги никто не делать\" и т.д. У триграммной модели меньше таких несогласованностей. В данном примере встречаются тавтология либо повторение: \"потому что женщина в пустыне даже понимая язык мира без объяснения причин потому что\"(потому что), \"они поговорили с одним человеком говорящим по-арабски а другой говорящим по-испански\" (поговорили, говорящим), \"молодой человек обнаружил что человек предал меня\" (человек) и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['А_л', 'х_и', 'м_и', 'к_ ', 'в', 'з', 'я_л', ' _к', 'н_и', 'г_у', ',_ ', 'к_о', 'т_о', 'р_у', 'ю_ ', 'п_р', 'и_н', 'е_с', ' _к', 'т_о', '-_т', 'о_ ', 'в', ' _к', 'а_р', 'а', 'в_а', 'н', '.']]\n",
      "[['А_л_х_и', 'м_и_к_ ', 'в_з', 'я_л', ' _к_н_и', 'г_у_,_ ', 'к_о_т_о', 'р_у_ю_ ', 'п_р_и_н', 'е_с', ' _к_т_о', '-_т_о_ ', 'в_ _к', 'а_р_а', 'в_а_н', '.']]\n",
      "[['А_л_х_и_м_и_к_ ', 'в_з_я_л', ' _к_н_и', 'г_у_,_ ', 'к_о_т_о', 'р_у_ю_ ', 'п_р_и_н_е_с', ' _к_т_о', '-_т_о_ ', 'в_ _к', 'а_р_а', 'в_а_н', '.']]\n"
     ]
    }
   ],
   "source": [
    "#!wget https://raw.githubusercontent.com/PetrFil/ComplingHSE/master/A.txt\n",
    "from gensim.summarization.textcleaner import split_sentences\n",
    "from gensim.models import Phrases\n",
    "coelho = open('A.txt', encoding = 'utf-8').read()\n",
    "sentences_coelho = list(split_sentences(coelho))\n",
    "symbols_coelho = []\n",
    "for i in range(len(sentences_coelho)):\n",
    "  symbols_coelho.insert(i, list(sentences_coelho[i]))\n",
    "p1 = Phrases(symbols_coelho, min_count=1, scoring = 'npmi', threshold = 0)\n",
    "p2 = Phrases(p1[symbols_coelho], scoring = 'npmi', threshold = -1)\n",
    "p3 = Phrases(p2[p1[symbols_coelho]],scoring = 'npmi', threshold = -1)\n",
    "print (list(p1[symbols_coelho])[:1])\n",
    "print(list(p2[p1[symbols_coelho]])[:1])\n",
    "print (list(p3[p2[p1[symbols_coelho]]])[:1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
